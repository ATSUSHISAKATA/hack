{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression 0.864\n",
      "RandomForestClassifier 0.888\n",
      "SVC 0.896\n",
      "VotingClassifier 0.912\n"
     ]
    }
   ],
   "source": [
    "#投票分類\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.datasets import make_moons\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#moonセット利用\n",
    "X,y=make_moons(n_samples=500,noise=0.3,random_state=42)    ##データの量が多いとSVCがアンサンブルを超す？\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,random_state=42)\n",
    "\n",
    "log_clf=LogisticRegression()\n",
    "rnd_clf=RandomForestClassifier()\n",
    "svm_clf=SVC(probability=True)\n",
    "\n",
    "voting_clf= VotingClassifier(\n",
    "    estimators=[(\"lr\",log_clf),(\"rf\",rnd_clf),(\"svc\",svm_clf)],\n",
    "    voting=\"soft\")\n",
    "voting_clf.fit(X_train,y_train)\n",
    "\n",
    "#正解率測定\n",
    "from sklearn.metrics import accuracy_score\n",
    "for clf in (log_clf,rnd_clf,svm_clf,voting_clf):\n",
    "    clf.fit(X_train,y_train)\n",
    "    y_pred=clf.predict(X_test)\n",
    "    print(clf.__class__.__name__,accuracy_score(y_test,y_pred))\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.904\n"
     ]
    }
   ],
   "source": [
    "#バギング　ペースティング\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.datasets import make_moons\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X,y=make_moons(n_samples=500,noise=0.3,random_state=42)    ##データの量が多いとSVCがアンサンブルを超す？\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,random_state=42)\n",
    "\n",
    "#バギング　OOB検証\n",
    "bag_clf=BaggingClassifier(\n",
    "    DecisionTreeClassifier(),n_estimators=500,bootstrap=True,n_jobs=-1,oob_score=True)\n",
    "bag_clf.fit(X_train,y_train)\n",
    "bag_clf.oob_score_\n",
    "from sklearn.metrics import accuracy_score\n",
    "y_pred=bag_clf.predict(X_test)\n",
    "print(accuracy_score(y_pred,y_test))\n",
    "\n",
    "bag_clf.oob_decision_function_\n",
    "\n",
    "#ランダムフォレスト\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rnd_clf=RandomForestClassifier(n_estimators=500, max_leaf_nodes=16,n_jobs=-1)\n",
    "rnd_clf.fit(X_train,y_train)\n",
    "\n",
    "y_pred_rf=rnd_clf.predict(X_test)\n",
    "\n",
    "bag_clf=BaggingClassifier(\n",
    "    DecisionTreeClassifier(splitter=\"random\",max_leaf_nodes=16),\n",
    "    n_estimators=500, max_samples=1.0,bootstrap=True,n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.896"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.datasets import make_moons\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X,y=make_moons(n_samples=500,noise=0.3,random_state=42)    ##データの量が多いとSVCがアンサンブルの精度を超す？\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,random_state=42)\n",
    "\n",
    "#AdaBoost分類器\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "ada_clf=AdaBoostClassifier(\n",
    "    DecisionTreeClassifier(max_depth=1),\n",
    "    n_estimators=200, algorithm=\"SAMME.R\",learning_rate=0.5)\n",
    "ada_clf.fit(X_train,y_train)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "y_pred=ada_clf.predict(X_test)\n",
    "accuracy_score(y_pred,y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.75026781]\n"
     ]
    }
   ],
   "source": [
    "##勾配ブースティング木\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "X=np.random.rand(100,1)-0.5  ##〇以上1未満の乱数\n",
    "y=3*X[:,0]**2+0.05*np.random.randn(100)\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "tree_reg1=DecisionTreeRegressor(max_depth=2)\n",
    "tree_reg1.fit(X,y)\n",
    "\n",
    "y2=y-tree_reg1.predict(X)\n",
    "tree_reg2=DecisionTreeRegressor(max_depth=2)\n",
    "tree_reg2.fit(X,y2)\n",
    "y3=y2-tree_reg2.predict(X)\n",
    "tree_reg3=DecisionTreeRegressor(max_depth=2)\n",
    "tree_reg3.fit(X,y3)\n",
    "\n",
    "X_new = np.array([[0.8]])\n",
    "y_pred=sum(tree.predict(X_new) for tree in (tree_reg1, tree_reg2,tree_reg3))\n",
    "\n",
    "print(y_pred)\n",
    "\n",
    "#勾配ブースティング木　sklearn使用\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "gbrt=GradientBoostingRegressor(max_depth=2,n_estimators=3,learning_rate=1.0)\n",
    "gbrt.fit(X,y)\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "X_train,X_val,y_train,y_val=train_test_split(X,y)\n",
    "\n",
    "gbrt=GradientBoostingRegressor(max_depth=2,n_estimators=120)\n",
    "gbrt.fit(X_train,y_train)\n",
    "\n",
    "errors=[mean_squared_error(y_val,y_pred) for y_pred in gbrt.staged_predict(X_val)]\n",
    "bst_n_estimators=np.argmin(errors)+1\n",
    "\n",
    "gbrt_best=GradientBoostingRegressor(max_depth=2,n_estimators=bst_n_estimators)\n",
    "gbrt_best.fit(X_train,y_train)\n",
    "gbrt_best.predict(X_new)\n",
    "\n",
    "gbrt=GradientBoostingRegressor(max_depth=2,warm_start=True)\n",
    "\n",
    "min_val_error=float(\"inf\")\n",
    "error_going_up=0\n",
    "for n_estimators in range(1,120):\n",
    "    gbrt.n_estimators=n_estimators\n",
    "    gbrt.fit(X_train,y_train)\n",
    "    y_pred=gbrt.predict(X_val)\n",
    "    val_error=mean_squared_error(y_val,y_pred)\n",
    "    if val_error < min_val_error:\n",
    "        min_val_error=val_error\n",
    "        error_going_up=0\n",
    "    else:\n",
    "        error_going_up+=1\n",
    "        if error_going_up==5:\n",
    "            break\n",
    "\n",
    "            \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-rmse:0.22055\n",
      "[1]\tvalidation_0-rmse:0.16547\n",
      "[2]\tvalidation_0-rmse:0.12243\n",
      "[3]\tvalidation_0-rmse:0.10044\n",
      "[4]\tvalidation_0-rmse:0.08467\n",
      "[5]\tvalidation_0-rmse:0.07344\n",
      "[6]\tvalidation_0-rmse:0.06728\n",
      "[7]\tvalidation_0-rmse:0.06383\n",
      "[8]\tvalidation_0-rmse:0.06125\n",
      "[9]\tvalidation_0-rmse:0.05959\n",
      "[10]\tvalidation_0-rmse:0.05902\n",
      "[11]\tvalidation_0-rmse:0.05852\n",
      "[12]\tvalidation_0-rmse:0.05844\n",
      "[13]\tvalidation_0-rmse:0.05801\n",
      "[14]\tvalidation_0-rmse:0.05747\n",
      "[15]\tvalidation_0-rmse:0.05772\n",
      "[16]\tvalidation_0-rmse:0.05778\n",
      "110 ms ± 444 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "48.2 ms ± 622 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "#XGBoost\n",
    "import xgboost\n",
    "\n",
    "xgb_reg=xgboost.XGBRegressor()\n",
    "xgb_reg.fit(X_train,y_train)\n",
    "y_pred=xgb_reg.predict(X_val)\n",
    "\n",
    "xgb_reg.fit(X_train,y_train,eval_set=[(X_val,y_val)],early_stopping_rounds=2)\n",
    "y_pred=xgb_reg.predict(X_val)\n",
    "\n",
    "%timeit xgboost.XGBRegressor().fit(X_train,y_train) \n",
    "%timeit GradientBoostingRegressor().fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest_clf=RandomForestClassifier(n_estimators=10,random_state=42) ##木のパラメータ指定　 ##mnist データサイズ指定　忘れないように\n",
    "for estimator in estimators:   ###for を使って見やすく簡潔に\n",
    "    print([estimator.score(X_val,y_val) for estimator in estimators])   ##属性指定　.scoreなどを用いて、accuracy_scoreではなくて"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
